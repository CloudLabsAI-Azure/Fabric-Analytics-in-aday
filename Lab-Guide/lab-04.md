Microsoft Fabric
Fabric Analyst in a Day
实验 4
版本：2024 年 3 月


## 目录
简介	3
数据流 Gen2	3
任务 1：将Snowflake 查询复制到数据流	3
任务 2：创建与Snowflake 的连接	5
任务 3：为Supplier 和PO 查询配置数据目标	7
任务 4：重命名并发布 Snowflake 数据流	9
任务 5：将Dataverse 查询复制到数据流	10
任务 6：创建与 Dataverse 的连接	12
任务 7：为Customer 查询创建数据目标	13
任务 8：发布并重命名 Dataverse 数据流	15
任务 9：将SharePoint 查询复制到数据流	17
任务 10：创建 SharePoint 连接	19
任务 11：为People 查询配置数据目标	20
任务 12：发布并重命名 SharePoint 数据流	22
参考	25

## 简介
在我们的应用场景中，供应商数据位于Snowflake 中，客户数据位于 Dataverse 中，员工数据位于 SharePoint 中。所有这些数据源都会在不同时间更新。为了最大限度地减少数据流的数据刷新次数，我们将为每个数据源创建单独的数据流。
**注意**：单个数据流支持多个数据源。本实验结束后，您将学会：
•	如何使用数据流Gen2 连接到 Snowflake 并将数据引入 Lakehouse
•	如何使用数据流Gen2 连接到 SharePoint 并将数据引入 Lakehouse
•	如何使用数据流Gen2 连接到 Dataverse 并将数据引入 Lakehouse

## 数据流 Gen2
### 任务 1：将Snowflake 查询复制到数据流
1.	让我们导航回到您在实验 2  任务 9 中创建的 Fabric 工作区 FAIAD_<username>。
2.	在顶部菜单中，选择**新建-> 数据流 Gen2。**

您将导航到**数据流页面**。现在我们已经熟悉了数据流，我们接下来从Power BI Desktop 复制查询到数据流。

3.	如果您还未打开**FAIAD.pbix**，请打开它。它位于您的实验环境的**C:\FAIAD\Reports** 文件夹中。
4.	从功能区中选择**主页 -> 转换数据**。Power Query 窗口随即打开。您在之前的实验中注意到，左侧面板中的查询是按数据源整理的。
5.	Power Query 窗口随即打开。从左侧面板中的 SnowflakeData 文件夹下，按 **Ctrl+ 选择或**
Shift+ 选择以下查询：
a.	SupplierCategories
b.	Suppliers
c.	Supplier
d.	PO
e.	PO Line Items
6.	**右键单击**并选择**复制**。
7.	导航回到**浏览器**。
8.	在**数据流窗格**中，选择**中间窗格**，然后输入  **Ctrl+V**（目前不支持右键单击粘贴）。如果您使用的是 MAC 设备，请使用 Cmd+V 进行粘贴。

   **注意**：如果您在实验环境中工作，请选择屏幕右上角的省略号。使用滑块**启用** **VM 本地剪贴板**。在对话框上，选择“确定”。粘贴查询后，您可以禁用此选项。

 ## 任务 2：创建与Snowflake 的连接
请注意，五个查询已粘贴，现在左侧显示“查询”面板。由于我们没有为Snowflake 创建连接，因此您将看到一条警告消息，要求您配置连接。
1.	选择**配置连接**。
2.	“连接到数据源”对话框随即打开。在**连接**下拉列表中，确保选择**创建新连接**。
3.	**身份验证种类**应为 **Snowflake**。
4.	**输入Snowflake 用户名和密码**，其位于“环境变量”选项卡中（“实验指南”选项卡旁边）。
5.	选择**连接**。


连接已建立，您可以在预览面板中查看数据。请自行浏览查询的应用步骤。Suppliers 查询基本上包含供应商的详细信息，SupplierCategories 顾名思义包含供应商的类别。这两个表与我们需要的列联接，以创建 Supplier 维度。同样，我们将PO Line Items 与PO 合并，以创建PO 事
实。现在我们需要将 Supplier 和PO 数据引入到 Lakehouse。

6.	如前所述，我们不会暂存任何此类数据。因此右键单击查询窗格中的 Supplier 查询，并选择启用暂存以删除复选标记。

7.	同样，右键单击 **PO** 查询。选择**启用暂存**以删除复选标记。
**注意**：我们不必为其他三个查询禁用暂存，因为在 Power BI Desktop（这些查询是从这里复制而来）中已经禁用了“启用加载”。

## 任务 3：为Supplier 和 PO 查询配置数据目标
1.	选择 **Supplier** 查询。
2.	在功能区中，选择**主页-> 添加数据目标-> 湖屋**。
3.	连接到数据目标”对话框随即打开。从**连接下拉菜单**中选择  **Lakehouse（无）**。
4.	选择**下一步**。
5.	“选择目标”对话框随即打开。务必**选中新建表单选按钮**，因为我们要创建一个新表。
6.	我们想要在之前创建的 Lakehouse 中创建表。在左侧面板中，导航到**湖屋-> FAIAD_<username>**。
7.	选择 **lh_FAIAD**.
8.	将表名称保留为 **Supplier**
9.	选择**下一步**.
10.	选择目标设置”对话框随即打开。这次我们将使用自动设置，因为这将对数据进行全面 更新。此外，它还会根据需要重命名列。选择**保存设置**。
11.	您将会导航回到**Power Query 窗口**。请注意，**右下角的数据目标**设置为**湖屋**。同样，为PO 查询设置数据目标。完成后，您的PO 查询应将数据目标设置为湖屋，如下面的屏幕截图所示。

## 任务 4：重命名并发布Snowflake 数据流
1.	从屏幕顶部，选择 **Dataflow 2 旁边的箭头**重命名。
2.	在对话框中，将名称更改为 **df_Supplier_Snowflake**
3.	点击 **Enter** 键以保存名称更改。
4.	在右下角，选择**发布**。

   您将导航回到 **FAIAD_<username> 工作区**。发布数据流可能需要一些时间。现在我们创建一个从 Dataverse 引入数据的数据流。


任务 5：将Dataverse 查询复制到数据流
1.	在顶部菜单中，选择**新建-> 数据流 Gen2**。

   您将导航到**数据流页面**。现在我们已经熟悉了数据流，我们接下来从Power BI Desktop 复制查询到数据流。

2.	如果您还未打开**FAIAD.pbix**，请打开它。它位于您的实验环境的**C:\FAIAD\Reports** 文件夹中。
3.	从功能区中选择**主页 -> 转换数据**。Power Query 窗口随即打开。您在之前的实验中注意到，左侧面板中的查询是按数据源整理的。
4.	Power Query 窗口随即打开。在左侧面板中的DataverseData 文件夹下，按C**trl+ 选择**以下查询：
a.	BabyBoomer
b.	GenX
c.	GenY
d.	GenZ
e.	Customer
5.	**右键单击**并选择**复制**
6.	导航回到浏览器中的**数据流页面**。
7.	在**数据流窗格**中，输入 **Ctrl+V**（目前不支持右键单击粘贴）。如果您使用的是 MAC 设备， 请使用 Cmd+V 进行粘贴。
注意：如果您在实验环境中工作，请选择屏幕右上角的省略号。使用滑块启用 VM 本地剪贴板。在对话框上，选择“确定”。粘贴查询后，您可以禁用此选项。

**注意**：如果您在实验环境中工作，请选择屏幕右上角的省略号。使用滑块**启用 VM 本地剪贴板**。在对话框上，选择“确定”。粘贴查询后，您可以禁用此选项。


## 任务 6：创建与Dataverse 的连接
请注意，五个查询已粘贴，现在左侧显示“查询”面板。由于我们没有为 Dataverse 创建连接，因此您将看到一条警告消息，要求您配置连接。
1.	选择**配置连接**。
2.	“连接到数据源”对话框随即打开。在**连接下拉列表**中，确保**选择创建新连接**。
3.	**身份验证种类**中应为**组织帐户**。
4.	选择**连接**。


## 任务 7：为 Customer 查询创建数据目标
连接已建立，您可以在预览面板中查看数据。请自行浏览查询的应用步骤。客户数据按类别提 供：BabyBoomer、GenX、GenY 和GenZ。追加这四个查询以创建 Customer 查询。现在我们需要将客户数据引入到 Lakehouse。
1.	如前所述，我们不会暂存任何此类数据。因此**右键单击**查询窗格中的 **Customer** 查询，并选择**启用暂存**以删除复选标记。
2.  选择 **Customer** 查询。
3.	在功能区中，选择**主页-> 添加数据目标-> 湖屋**.
4.	“连接到数据目标”对话框随即打开。从**连接下拉菜单中选择**  **Lakehouse**（无）。
5.	选择**下一步**。
6.	“选择目标”对话框随即打开。务必选中**新建表单选按钮**，因为我们要创建一个新表。
7.	我们想要在之前创建的 Lakehouse 中创建表。在左侧面板中，导航到**湖屋-> FAIAD_<username>**
8.	选择 **lh_FAIAD**
9.	将表名称保留为 **Customer**
10.	选择**下一步**。
11.	“选择目标设置”对话框随即打开。这次我们将使用自动设置，因为这将对数据进行全面 更新。此外，它还会根据需要重命名列。选择**保存设置**。

# # 任务 8：发布并重命名Dataverse 数据流
1.	您将会导航回到 **Power Query 窗口**。请注意，**右下角的数据目标设置为湖屋**。
2.	在右下角，选择**发布**。
   
   **注意**：您将导航回到 **FAIAD_<username>**  **工作区**。发布数据流可能需要一些时间。
   
3.	我们正在使用的数据流是 Dataflow 2。在继续下面的步骤之前，我们先将其重命名。点击Dataflow 2 旁边的**省略号 (…)**。选择**属性**。

4.	“数据流属性”对话框随即打开。将**名称**更改为 **df_Customer_Dataverse**
5.	在**说明**文本框中，添加 **Dataflow to ingest Customer data from Dataverse to Lakehouse**。
6.	选择**保存**。

您将导航回到 **FAIAD_<username>** **工作区**。现在我们创建一个从 SharePoint 引入数据的数据流。


## 任务 9：将SharePoint 查询复制到数据流
1.	在顶部菜单中，选择**新建****-> 数据流 Gen2**。

您将导航到**数据流页面**。现在我们已经熟悉了数据流，我们接下来从Power BI Desktop 复制查询到数据流。

2.	如果您还未打开**FAIAD.pbix**，请打开它。它位于您的实验环境的**C:\FAIAD\Reports** 文件夹中。
3.	从功能区中选择**主页 -> 转换数据**。Power Query 窗口随即打开。您在之前的实验中注意到，左侧面板中的查询是按数据源整理的。
4.	Power Query 窗口随即打开。在左侧面板的 SharepointData 文件夹下，**选择People** 查询。
 
5.	**右键单击**并选择**复制**。

6.	导航回到浏览器中的**数据流屏幕**。
7.	在**数据流窗格**中，输入  **Ctrl+V**（目前不支持右键单击粘贴）。
**注意**：如果您在实验环境中工作，请选择屏幕右上角的省略号。使用滑块**启用 VM** **本地剪贴板**。在对话框上，选择“确定”。粘贴查询后，您可以禁用此选项。
请注意，查询已粘贴并在左侧面板中可用。由于我们没有为 SharePoint 创建连接，因此您将看到一条警告消息，要求您配置连接。
 
## 任务 10：创建 SharePoint 连接
1.	选择**配置连接**。

2.	“连接到数据源”对话框随即打开。在**连接**下拉列表中，确保选择**创建新连接**。
3.	**身份验证种类**中应为**组织帐户**。
4.	选择**连接**。

 
## 任务 11：为 People 查询配置数据目标
连接已建立，您可以在预览面板中查看数据。请自行浏览查询的应用步骤。现在我们需要将人 员数据引入到 Lakehouse。
1.	如前所述，我们不会暂存任何此类数据。因此**右键单击**查询窗格中的  **People**  查询，并选择
**启用暂存**以删除复选标记。

2.	选择 **People** 查询。
3.	在功能区中，选择**主页-> 添加数据目标-> 湖屋**。

4.	“连接到数据目标”对话框随即打开。从**连接下拉菜单**中选择  **Lakehouse（无）**。
 
5.	选择**下一步**。

6.	“选择目标”对话框随即打开。务必选**中新建表单选按钮**，因为我们要创建一个新表。
7.	我们想要在之前创建的 Lakehouse 中创建表。在左侧面板中，导航到**湖屋****-> FAIAD_<username>**。
8.	选择 **lh_FAIAD**
9.	将表名称保留为 **People**
10.	选择**下一步**。

 
11.	“选择目标设置”对话框随即打开。这次我们将使用自动设置，因为这将对数据进行全面 更新。此外，它还会根据需要重命名列。选择**保存**设置。




# # 任务 12：发布并重命名 SharePoint 数据流
1.	您将会导航回到 **Power Query 窗口**。请注意，**右下角**的数据目标设置为**湖屋**。
2.	在右下角，选择**发布**。

**注意**：您将导航回到 **FAIAD_<username>  工作区**。发布数据流可能需要一些时间。
 
3.	我们正在使用的数据流是 Dataflow 2。在继续下面的步骤之前，我们先将其重命名。点击Dataflow 2 旁边的**省略号 (…)**。选择**属性**。

4.	“数据流属性”对话框随即打开。将**名称**更改为  **df_People_SharePoint**
5.	在**说明**文本框中，添加 **Dataflow to ingest People data from SharePoint to Lakehouse**。
 
6.	选择**保存**。

您将导航回到 **FAIAD_<username>** **工作区**。我们现在已将所有数据引入到 Lakehouse。在下一个实验中，我们将安排数据流刷新。




 
参考
Fabric Analyst in a Day (FAIAD) 介绍了Microsoft Fabric 中提供的一些主要功能。在服务菜单中， “帮助 (?)”部分包含指向一些优质资源的链接。

以下更多参考资源可帮助您进行与Microsoft Fabric 相关的后续步骤。
•	请参阅博客文章以阅读完整的Microsof t Fabric GA 公告
•	通过引导式教程探索 Fabric
•	注册 Microsof t Fabric 免费试用版
•	访问 Microsof t Fabric 网站
•	通过探索 Fabric 学习模块学习新技能
•	探索 Fabric 技术文档
•	阅读有关Fabric 入门指南的免费电子书
•	加入 Fabric 社区发布问题、分享反馈并向他人学习
 
阅读更多深度Fabric 体验公告博客：
•	Fabric 中的Data Factory 体验博客
•	Fabric 中的Synapse Data Engineering 体验博客
•	Fabric 中的Synapse Data Science 体验博客
•	Fabric 中的Synapse Data Warehousing 体验博客
•	Fabric 中的Synapse Real-Time Analytics 体验博客
•	Power BI 公告博客
•	Fabric 中的Data Activator 博客
•	Fabric 中的管理和治理博客
•	Fabric 中的OneLake 博客
•	Dataverse 和Microsof t Fabric 集成博客


© 2023 Microsoft Corporation.保留所有权利。使用此演示/实验即表示您已同意以下条款：
本演示/实验中的技术/功能由 Microsoft Corporation 出于获取反馈和提供学习体验的目的提供。只能将本演示/实验用于评估这些技术特性和功能以及向Microsoft 提供反馈。不得用于任何其他用途。不得对此演示/实验或其任何部分进行修改、复制、分发、传送、显示、 执行、复制、公布、许可、转让、销售或基于以上内容创建衍生作品。
严禁将本演示/实验（或其任何部分）复制到任何其他服务器或位置以便进一步复制或再分发。
本演示/实验出于上述目的，在不涉及复杂设置或安装操作的模拟环境中提供特定软件技术
/产品特性和功能，包括潜在的新功能和概念。本演示/实验中展示的技术/概念可能不是完 整的功能，可能会以不同于最终版本的工作方式工作。我们也可能不会发布此类功能或概念的最终版本。在物理环境中使用此类特性和功能的体验可能也有所不同。
反馈。如您针对本演示/实验中所述的技术特性、功能和/或概念向 Microsoft 提供反馈，则意味着您向Microsoft  无偿提供以任何方式、出于任何目的使用和分享您的反馈并将其商业化的权利。您同样无偿为第三方提供其产品、技术和服务使用或配合使用包含此反馈的
Microsoft 软件或服务的任何特定部分所需的任何专利权。如果根据某项许可的规定，
Microsoft  由于在其软件或文档中包含了您的反馈需要向第三方授予该软件或文档的许可， 请不要提供这样的反馈。这些权利在本协议终止后继续有效。
 
对于本演示/实验，Microsoft Corporation 不提供任何明示、暗示或法定的保证和条件，包括有关适销性、针对特定目的的适用性、所有权和不侵权的所有保证和条件。对于使用本 演示/实验产生的结果或输出内容的准确性，或者出于任何目的包含本演示/实验中的信息的适用性，Microsoft 不做任何保证或陈述。
免责声明
本演示/实验仅包含 Microsoft Power BI 的部分新功能和增强功能。在产品的后续版本中， 部分功能可能有所更改 。在本演示/实验中，可了解部分新功能，但并非全部新功能。





