# Microsoft Fabric
## Fabric Analyst in a Day
ラボ 1
バージョン: 2024 年 3 月


## 目次
ドキュメントの構造	3 <br>
シナリオ / 問題の説明	3 <br>
Power BI Desktop レポートの概要	5 <br>
    タスク 1: ラボ環境で Power BI Desktop を設定する	5 <br>
    タスク 2: Power BI Desktop レポートを分析する	8 <br>
    タスク 3: Power Query を確認する	12 <br>
リファレンス	16 <br>

# ドキュメントの構造

このラボでは、実行する手順だけでなく、視覚的にわかりやすいように、手順に関連するス クリーンショットも提示されます。各スクリーンショットでは、ユーザーが注目する必要の ある領域が、オレンジのボックスで強調表示されて示されます。

# シナリオ/ 問題の説明

Fabrikam, Inc. は、ノベルティ商品の卸売業者です。卸売業者である Fabrikam の顧客のほとんどは、個人に再販する会社です。Fabrikam は、専門店、スーパーマーケット、コンピューター販売店、観光名所の店など、アメリカ合衆国全土の小売顧客に販売しています。また、Fabrikam では、Fabrikam に代わって製品の販売促進を行う代理店のネットワークを通じて、他の卸売業者にも販売しています。現在、Fabrikam の顧客はすべてアメリカ合衆国に拠点を置いていますが、同社では他の国や地域への拡大を推進しようと考えています。

あなたは営業チームのデータアナリストです。データセットの収集、クリーンアップ、解釈を行ってビジネス上の問題を解決します。また、チャートやグラフなどの視覚エフェクトをまとめたり、レポートを作成したり、それらを組織の意思決定者にプレゼンしたりもします。

データから貴重な分析情報を引き出すには、さまざまなシステムからデータを取得し、ク リーンアップして、まとめてマッシュアップする必要があります。データは次のソースから 取得できます。

- **販売データ:** ERP システムから取得します。データは ADLS Gen2 データベースまたは <br>
      Databricks に格納されます。毎日正午 (午後 0 時) に更新されます。<br>

- **仕入先データ:** さまざまな仕入先から取得します。データは Snowflake データベースに格納されます。毎日真夜中 (午前 0 時) に更新されます。<br>

- **顧客データ:** Customer Insights から取得します。データは Dataverse に格納されます。データは常に最新の状態です。<br>

- **従業員データ:**  人事システムから取得します。エクスポート ファイルとして<br>
      SharePoint フォルダーに格納されます。毎朝午前 9 時に更新されます。<br>

 ![](./Images/lab-01/image006.jpg) 

あなたは現在、Power BI Premium で上記のソース システムからデータを取得するデータセットを構築しています。その目的は、自分のレポート作成のニーズを満たし、エンド ユーザーにセルフサービス機能を提供することです。モデルの更新には Power Query を使います。


## 直面している課題:

- 各種データ ソースごとに異なる更新時間に対応するには、1 日に少なくとも 3 回はデータセットを更新する必要があります。

- ソース システムで発生したすべての更新を取得するために毎回完全な更新を行う必要があるため、更新に長い時間がかかります。

- 取得元のデータ ソースでエラーが発生すると、データセットの更新が中断されま す。従業員ファイルが時間どおりにアップロードされず、データセットの更新が中 断されてしまうことが何度もあります。

- データ モデルに変更を加えるのに非常に長い時間がかかります。データ サイズが大きくて変換が複雑だと、Power Query によるプレビューの更新に時間がかかるためです。

- 社内標準は Mac ですが、Power BI Desktop を使用するにはWindows PC が必要です。

Microsoft Fabric について聞いたあなたは、それを使って課題に対処できるかどうかを見てみることにしました。

# Power BI Desktop レポートの概要



