# Microsoft Fabric
## Fabric Analyst in a Day
ラボ 3
バージョン: 2024 年 3 月
 	 
 
## 目次
概要	3<br>
Dataflow Gen2	4<br>
タスク 1: Dataflow Gen2 を作成する	4<br>
タスク 2: ADLS Gen2 への接続を作成する	5<br>
タスク 3: ADLS Gen2 フォルダーの基本クエリを作成する	8<br>
タスク 4: Cities クエリを作成する	10<br>
タスク 5: Countries クエリを作成する	13<br>
タスク 6: コピーを使用して States を作成する – オプション1	15<br>
タスク 7: コピーを使用して Geo クエリを作成する – オプション 2	17<br>
タスク 8: Geo クエリのデータ送信先を構成する	20<br>
タスク 9: Dataflow を公開する	24<br>
タスク 10: Dataflow の名前を変更する	25<br>
タスク 11: Dataflow 内の残りのクエリを構築する	27<br>
タスク 12: 残りのクエリのデータ送信先を構成する	29<br>
リファレンス	33<br>

 
# 概要

このシナリオでは、ERP システムから入ってきた Sales データがADLS Gen2 に格納されています。毎日正午 (午後 0 時) に更新されます。このデータを変換して Lakehouse に取り込み、モデルで使用する必要があります。

このデータは複数の方法で取り込むことができます。

- ショートカットを使用する。この方法ではデータを変換できません。
- Notebooks を使用する。この場合はコードを書く必要があります。開発者にとってやりやすいアプローチです。
- Dataflow Gen2 を使用する。Power Query や Dataflow Gen1 についてはおそらくなじみがあることと思います。Dataflow Gen2 はその名前が示すように、新しいバージョン
  の Dataflow です。Power Query と Dataflow Gen1 のすべての機能に加え、データを変換して複数のデータ ソースに取り込む機能が追加されています。これについては以降のラボで紹介します。
- データ パイプラインを使用する。データ パイプラインはオーケストレーション ツー
  ルです。アクティビティに調整を加え、データを抽出、変換して取り込むことができます。ここではデータパイプラインを使用して Dataflow Gen2 のアクティビティを実行し、抽出、変換、取り込みを行います。

まずは Dataflow Gen2 から始め、データ ソースへの接続を作成し、必要な変換を行います。その後、データ パイプラインを使用して Dataflow Gen2 に調整を加え、実行します。

このラボを終了すると、次のことが学べます。
- Dataflow Gen2 の作成方法
- Dataflow Gen2 を使用して ADLS Gen2 に接続し、データを変換する方法
- データを Lakehouse に取り込む方法
 
## Dataflow Gen2

## タスク 1: Dataflow Gen2 を作成する
1.	ラボ 2 のタスク 9 で作成した Fabric ワークスペースに戻ります。

2.	前のラボの終了後に別の場所に移動していない場合は、Lakehouse    の画面が表示されて
    います。別の場所に移動した場合でも問題ありません。画面の左下の Fabric エクスペリエンス セレクター アイコンを選択します。

3.	開いているFabric エクスペリエンスダイアログから Data Factory を選択します。Data Factory にはデータの抽出、変換、取り込みに必要なワークロードがあります。

   ![](../Images/lab-02/image015.jpg)

   ![](../Images/lab-02/image018.jpg)
 
4.	Data Factory のホーム ページが表示されます。[新規] で、データフロー (Gen2) を選択します。
    Dataflow のページが表示されます。この画面は Dataflow Gen1 やPower Query の画面と似て
    いるため、見覚えがあることと思います。データを変換する機能とともに、さまざまなデー タソースに接続するためのオプションを利用できます。ADLS Gen2 データソースに接続
    し、いくつかの変換を実行してみましょう。


## タスク 2:  ADLS Gen2 への接続を作成する
1.	リボンでホーム -> データを取得 -> 詳細の順に選択します。

   ![](../Images/lab-02/image021.jpg)
 
2.	データを取得のデータ   ソースの選択ダイアログが表示されます。検索ボックスに入力す
    ることでデータ ソースを検索できます。左パネルには、空のテーブルまたは空のクエリを使用するオプションがあります。ファイルをアップロードするための新しいオプショ

   ![](../Images/lab-02/image024.jpg)

    ンもあります。このオプションについては、後続のラボで詳しく見ていきます。ここで は、画面右隅にある詳細表示 -> をクリックしてみましょう。
    これで、利用可能なすべてのデータ ソースが表示されます。データ ソースをファイル、データベース、Microsoft Fabric、Power Platform、Azure などでフィルター処理するオプションがあります。

   ![](../Images/lab-02/image027.jpg) 

3.	上部のフィルター オプションから Azure を選択して、Azure のデータ ソースに絞り込みます。
 
4.	Azure Data Lake Storage Gen2 を選択します。

   ![](../Images/lab-02/image030.jpg)

5.	[データ ソースへの接続] ダイアログが表示されます。ADLS Gen2 データ ソースへの接続を作成する必要があります。接続設定 -> URL にリンク
    https://stvnextblobstorage.dfs.core.windows.net/fabrikam-sales/Delta-Parquet-Format を
    入力します。

   ![](../Images/lab-02/image033.jpg)

6.	[認証の種類] ドロップダウンから、アカウント キーを選択します。
 
7.	環境変数タブ ([ラボ ガイド] タブの横) から ADLS ストレージアカウントのアクセス キー
    をコピーし、アカウント キー テキストボックスに貼り付けます。

   ![](../Images/lab-02/image036.jpg)

8.	画面右下の次へを選択します。


## タスク 3: ADLS Gen2 フォルダーの基本クエリを作成する

   ![](../Images/lab-02/image042.jpg)

1.	接続が確立されると、フォルダー データのプレビュー画面が表示されます。ADLS  Gen2 フォルダーには多数のファイルがあります。その中のいくつかのファイルのデータが必 要です。作成を選択して、フォルダーへの接続を作成します。
 
2.	Power Query のダイアログに戻ります。これがADLS Gen2 のルート フォルダーへの接続
    になります。このクエリは後続のクエリで参照します。クエリの名前を変更しましょ う。右パネルのクエリの設定 ->プロパティ-> 名前で、名前を ADLS Base Folder for Geo に変更します。

3.	Dataflow Gen2 からのすべてのクエリは、デフォルトでステージング Lakehouse に読み込
    まれます。このラボではデータをステージングすることはありません。この読み込みを 無効にするには、左パネルで ADLS Base Folder クエリを右クリックします。
    注: ステージングは、データを使用する準備が整う前に、さらに変換するためにデータをステージングする必要がある場合に使用されます。

4.	ステージングを有効にするオプションをオフにします。

   ![](../Images/lab-02/image045.jpg)

    フォルダー内には、json と parquet という 2 つのファイル形式があります。

- Parquet  は、フラット カラムナストレージデータ形式を処理するために構築されたオープンソースファイル形式です。Parquet  は大量の複雑なデータを処理するのに適しており、データ圧縮のパフォーマンスが高く、幅広い種類のエンコーディングを処理できることで知られています。
- Json ファイルには、スキーマ (parquet ファイルのデータ型) などのメタデータが含まれています。

5.	必要なのは、必要なデータが含まれている parquet  ファイルのみです。拡張子列のド
    ロップダウン矢印を選択します。
 
6.	.json のチェックを外して、.parquet ファイルに絞り込みます。

7.	OK を選択します。

   ![](../Images/lab-02/image048.jpg)

これで、基本クエリが設定されました。すべてのGeo クエリでこのクエリを参照できます。


## タスク 4: Cities クエリを作成する
Sales データは、Geography、Product、SalesPerson、Date の細分性で入手できます。まず Geo ディメンションを取得するクエリを作成しましょう。Geo データは、次のサブフォルダーにある 3 つの異なるファイルで利用できます。
- Cities: Application.Cities
- Countries: Application.Countries
- State: Application.StateProvinces
これら 3 つのファイルの City、State、Country のデータを組み合わせて Geo ディメンションを作成する必要があります。

1.	まずは City から始めましょう。左パネルで、ADLS Base Folder for Geo を右クリックします。参照を選択して、ADLS Base Folder for Geo クエリを参照する新しいクエリを作成します。
 
   ![](../Images/lab-02/image051.jpg) 

2.	Folder Path 列のドロップダウン矢印を選択します。

   ![](../Images/lab-02/image054.jpg)

3.	テキスト フィルター-> 次の値を含む... を選択します。

   ![](../Images/lab-02/image060.jpg)

4.	行のフィルター処理ダイアログに、Application.Cities と入力します。

    注: 大文字と小文字が区別されます。
 
5.	OK を選択します。

   ![](../Images/lab-02/image063.jpg)

6.	データは 1 つの行に絞り込まれます。Content 列のBinary を選択します。

   ![](../Images/lab-02/image066.jpg)

7.	City のすべての詳細が表示されます。右パネルのクエリの設定 -> プロパティ-> 名前で、名前を Cities に変更します。

    注: スクリーンショットの右下隅で、クエリに適用されたステップが 4 つあることを確認し、クエリの読み込みが完了するのを待ちます。数分かかる場合があります。

   ![](../Images/lab-02/image069.jpg)

    右パネルの適用されたステップに、すべてのステップが登録されています。この動作は
    Power Query と似ています。次は、同様のプロセスに従って、Country クエリを作成しましょう。
 
## タスク 5: Countries クエリを作成する
1.	左パネルで、ADLS Base Folder for Geo を右クリックします。参照を選択して、ADLS Base Folder for Geo クエリを参照する新しいクエリを作成します。

   ![](../Images/lab-02/image072.jpg)

2.	Folder Path 列のドロップダウンを選択します。

   ![](../Images/lab-02/image075.jpg)

3.	テキスト フィルター-> 次の値を含む... を選択します。

   ![](../Images/lab-02/image081.jpg)

4.	行のフィルター処理ダイアログに、Application.Countries と入力します。

    注: 大文字と小文字が区別されます。
 
5.	OK を選択します。

   ![](../Images/lab-02/image083.jpg)

6.	データは 1 つの行に絞り込まれます。Content 列の Binary を選択します。

   ![](../Images/lab-02/image086.jpg)

7.	Country のすべての詳細が表示されます。右パネルのクエリの設定 -> プロパティ-> 名前
    で、名前を Countries に変更します。

    注: スクリーンショットの右下隅で、クエリに適用されたステップが 4 つあることを確認し、クエリの読み込みが完了するのを待ちます。数分かかる場合があります。

   ![](../Images/lab-02/image089.jpg)

次はState を取り込む必要がありますが、同じステップの繰り返しです。Power BI Desktop ファイルには既にクエリがあります。そこからクエリをコピーできるかどうかを見てみましょう。
 
## タスク 6: コピーを使用してStates を作成する– オプション 1
1.	まだ開いていない場合は、自分のラボ環境の C:\FAIAD\Reports  フォルダーにある
    FAIAD.pbix を開きます。

2.	リボンからホーム -> データの変換を選択します。Power Query ウィンドウが開きます。前のラボで確認したように、左パネルのクエリはデータ ソースごとに整理されています。

   ![](../Images/lab-02/image098.jpg)

3.	左パネルの ADLSData フォルダーにある States クエリを右クリックし、コピーを選択します。

   ![](../Images/lab-02/image104.jpg)

4.	ブラウザーに戻ります。作業中の Dataflow が表示されます。

5.	左パネルでクエリ パネルを選択し、Ctrl+V を押します (現時点では右クリックの貼り付けには対応していません)。MAC デバイスを使用している場合は、Cmd + V キーを使用し
    て貼り付けてください。
 
注:  ラボ環境で作業している場合は、画面の右側にある省略記号を選択してください。スライダーを使用して VM ネイティブクリップボードを有効にします。ダイアログで[OK] を選択します。クエリの貼り付けが済んだら、このオプションを無効にしてかまいません。


   ![](../Images/lab-02/image107.jpg)

ADLS Base Folder もコピーされることに注意してください。これは、States クエリがPower BI Desktop のADLS Base Folder を参照しているものの、似たクエリが既に存在するためです。これを解決しましょう。

6.	States クエリを選択します。

7.	右側のパネルの適用されたステップで、ソースを選択します。

8.	数式バーで、#"ADLS Base Folder" を #"ADLS Base Folder for Geo" に変更します。

   ![](../Images/lab-02/image113.jpg)
 
9.	数式バーの横にあるチェック マークをクリックするか、Enter  キーを押します。

   ![](../Images/lab-02/image116.jpg)

10.	これで ADLS Base Folder を削除できます。左パネルのクエリ セクションで ADLS Base Folder クエリを右クリックし、削除を選択します。

   ![](../Images/lab-02/image125.jpg)

11.	[クエリの削除] ダイアログが表示されます。削除を選択して確定します。
    注: クエリに適用されたステップが 4 つあることを確認し、クエリの読み込みが完了するまで待ちます。数分かかる場合があります。


## タスク 7: コピーを使用して Geo クエリを作成する– オプション 2
次は、これらのクエリをマージして Geo ディメンションを作成する必要があります。Power BI Desktop ファイルからクエリを再度コピーしてみましょう。今回は詳細エディターからコードをコピーします。
1.	Power BI Desktop ファイルの Power Query のウィンドウに戻ります。

2.	左パネルのクエリで、ADLSData フォルダーにある Geo クエリを選択します。
 
3.	リボンからホーム -> 詳細エディターを選択します。

   ![](../Images/lab-02/image128.jpg)

4.	詳細エディターのウィンドウが開きます。詳細エディターですべてのテキストを強調表 示します。

5.	右クリックして Copy を選択します。

   ![](../Images/lab-02/image131.jpg)

6.	ウィンドウの右上隅にある X を選択するか、完了を選択して、詳細エディターのウィンドウを閉じます。

7.	ブラウザーの Dataflow のウィンドウに戻ります。
 
8.	リボンからデータを取得 -> 空のクエリを選択します。

   ![](../Images/lab-02/image134.jpg)

9.	[データを取得] の[データソースへの接続] 詳細エディター ダイアログが開きます。エディターですべてのテキストを強調表示します。

10.	すべてのテキストを削除するには、キーボードで Delete  キーを押します。

11.	詳細エディターは空にする必要があります。次に、Ctrl+V を押して、Power BI Desktop の詳細エディターからコピーしたコンテンツを貼り付けます。

12.	次へを選択します。

   ![](../Images/lab-02/image137.jpg)
 
13.	これで、Geo ディメンションが作成されました。クエリの名前を変更しましょう。右パネルのクエリの設定 -> プロパティ-> 名前で、名前を Geo に変更します。

    注: クエリの読み込みが完了するまで待ちます。数分かかる場合があります。

    Geo がどのように作成されたかを理解するために、そのステップを一通り見てみましょう。右側のパネルの適用したステップで、ソースを選択します。数式バーを見るか、[設定] をクリックすると、このクエリのソースが Cities と States の結合であること      がわかります。ス
    テップを進めていくと、最初の結合結果が今度は Countries  と結合されていることがわかります。したがって、3 つのクエリはすべて Geo ディメンションの作成に使用されています。

    ![](../Images/lab-02/image143.jpg)


## タスク 8: Geo クエリのデータ送信先を構成する
これでディメンションが作成されました。次は、このデータを Lakehouse に取り込みましょう。これは Dataflow Gen2 で利用できるようになった新機能です。


   ![](../Images/lab-02/image155.jpg)

1.	前述したように、ここではこのデータを一切ステージングしません。そのため、Cities クエリを右クリックし、ステージングを有効にするを選択してチェックマークを外します。
 
2.	Countries クエリと Geo クエリでも同じステップを実行し、ステージングを有効にするの横にあるチェック マークを外します。

3.	Geo クエリを選択します。

4.	右下隅のデータ同期先の横にある + を選択します。

5.	ダイアログでレイクハウスを選択します。

   ![](../Images/lab-02/image164.jpg)

6.	[データ変換先に接続] ダイアログが開きます。Lakehouse への新しい接続を作成する必要があります。接続ドロップダウンで新しい接続の作成を選択し、認証の種類を組織アカ
    ウントに設定して、次へを選択します。

   ![](../Images/lab-02/image166.jpg)

7.	接続が作成されると、[宛先ターゲットの選択] ダイアログが開きます。新しいテーブルを作成しているため、新しいテーブル ラジオ ボタンがオンになっていることを確認してください。
 
8.	先ほど作成した Lakehouse  にテーブルを作成する必要があります。左パネルで、
    Lakehouse -> FAIAD_<ユーザー名> に移動します。

9.	lh_FAIAD を選択します。

10.	テーブル名は Geo のままにします。

11.	次へを選択します。

    ![](../Images/lab-02/image006.png)

12.	[宛先の設定を選択する] ダイアログが開きます。スライダーを使用して自動設定を無効にします。オプションを確認しましょう。
    既存のテーブルにデータを追加するオプションまたは置き換えるオプションがあること に注意してください。
    また、公開時のスキーマ   オプションがあります。スキーマを固定したままにするオプ
    ションがあります。または、時間が経つと変化する場合は、動的スキーマのオプション があります。
    "一部の列名には、サポートされていない文字が含まれています。問題を解決する必要が ありますか?" という警告が表示されます。レイクハウスでは列名にスペースを使用できません。[修正する] を選択すると、アンダースコアが追加されて列名のスペースが      置き換えられます。
注: [ソース] 列の右側のチェック ボックスを使用すると、レイクハウスに読み込む列だけを選択できます。

   ![](../Images/lab-02/image009.png)
 
13.	このシナリオでは、自動設定を使用します。自動設定を使用するスライダーを有効にし ます。宛先列の名前がアンダースコアで自動的に修正されることに注意してください。

14.	列マッピングを使用して、データフロー列を既存の列にマップできます。この場合、 それは新しいテーブルです。そのため、既定値を使用できます。設定の保存を選択し ます。

   ![](../Images/lab-02/image039.png)

 
## タスク 9: Dataflow を公開する
1.	Power Query のウィンドウに戻ります。右下隅を見ると、データの同期先がレイクハウスに設定されています。

   ![](../Images/lab-02/image057.png)

2.	Lakehouse を確認できるように、これらのクエリを公開しましょう。後で戻ってきてさらにクエリを追加する予定です。右下隅の公開を選択します。

3.	FAIAD_<ユーザー名> ワークスペースに自動的に戻ります。Dataflow が公開されるまで、しばらくかかる場合があります。済んだら、中央のペインまたは左側のパネルから
    lh_FAIAD レイクハウスを選択します。

   ![](../Images/lab-02/image078.png)
 
4.	Lakehouse のエクスプローラー画面が表示されます。左パネルで、lh_FAIAD -> テーブル
    を展開します。

5.	現在、Lakehouse には Geo テーブルがあります。Geo を展開し、すべての列を確認します。

6.	Geo テーブルを選択すると、右パネルにデータ プレビューが開きます。

   ![](../Images/lab-02/image092.png)

このテーブルのクエリに使用できる SQL エンドポイントもあります。このオプションについては、後続のラボで見ていきます。Geo  データが Lakehouse  に到達したことがわかったので、残りのデータを ADLS Gen2 から取り込みましょう。


## タスク 10: Dataflow の名前を変更する
1.	左のメニュー バーで、FAIAD_<ユーザー名>  を選択して、ワークスペースに戻ります。

2.	ここでは Dataflow 1 を操作しています。先に進む前に名前を変更しましょう。Dataflow 1
    の横にある 省略記号 (…) をクリックします。プロパティを選択します。
 
   ![](../Images/lab-02/image095.png)

3.	[Dataflow のプロパティ] ダイアログが開きます。名前を df_Sales_ADLS に変更します。

    注: Dataflow 名の前に df を追加します。これにより、検索と並び替えが容易になります。

4.	説明テキスト ボックスに、Dataflow to ingest Sales Data from ADLS to Lakehouse と入力します。

   ![](../Images/lab-02/image101.png)

5.	保存を選択します。
 
## タスク 11: Dataflow 内の残りのクエリを構築する
1.	FAIAD_<ユーザー名>  ワークスペースに自動的に戻ります。データフロー df_Sales_ADLS
    を選択して、データフローに戻ります。

   ![](../Images/lab-02/image110.png)

    容易に進められるように、Power BI Desktop からクエリをコピーできるかどうかを見てみましょう。

2.	まだ開いていない場合は、自分のラボ環境の C:\FAIAD\Reports  フォルダーにある
    FAIAD.pbix を開きます。

3.	リボンからホーム -> 変換を選択します。Power Query ウィンドウが開きます。

4.	左のクエリ パネルで、ADLSData から次のクエリを Ctrl+Select を押しながら選択します。
    a.	Product
    b.	Product Groups
    c.	Product Item Group
    d.	Product Details
    e.	Invoice
    f.	InvoiceLineItems
    g.	Sales
    h.	BuyingGroup
    i.	Reseller
    j.	Date
 
5.	右クリックしてコピーを選択します。

   ![](../Images/lab-02/image119.png)

6.	ブラウザーの Dataflow df_Sales_ADLS のウィンドウに戻ります。

7.	左パネルでクエリ パネルを選択し、Ctrl+V を押します (現時点では右クリックの貼り付けには対応していません)。MAC デバイスを使用している場合は、Cmd + V キーを使用して貼り付けてください。
    注:  ラボ環境で作業している場合は、画面の右側にある省略記号を選択してください。スライダーを使用して VM ネイティブクリップボードを有効にします。ダイアログで[OK] を選択します。クエリの貼り付けが済んだら、このオプションを無効にしてかまい 
    ません。

   ![](../Images/lab-02/image122.png)
 
8.	前述したように、ここではこのデータを一切ステージングしません。そのため、次のクエ
    リを右クリックし、ステージングを有効にするを選択してチェック マークを外します。
    a.	Product
    b.	Product Details
    c.	Reseller
    d.	Sales
    e.	Date

    注: Power BI Desktop で読み込みが無効になっている場合、Dataflow のステージングを無
    効にする必要はありません。したがって、Product Item Group、Product Groups などのステージングを無効にする必要はありません。
   
   ![](../Images/lab-02/image140.png)
 
    すべてのクエリが処理されていることを確認してください。完了したら、このデータを
    Lakehouse に取り込みましょう。


## タスク 12: 残りのクエリのデータ送信先を構成する
1.	Product クエリを選択します。

2.	リボンからホーム -> データ同期先の追加 -> レイクハウスを選択します。

   ![](../Images/lab-02/image146.png)

3.	[データ変換先に接続] ダイアログが開きます。接続ドロップダウンから Lakehouse (なし)
    を選択します。

4.	次へを選択します。

   ![](../Images/lab-02/image149.png)

5.	[宛先ターゲットの選択] ダイアログが開きます。新しいテーブルを作成しているため、
    新しいテーブル ラジオ ボタンがオンになっていることを確認してください。

6.	先ほど作成した Lakehouse  にテーブルを作成する必要があります。左パネルで、
    Lakehouse -> FAIAD_<ユーザー名> に移動します。

7.	lh_FAIAD を選択します。

8.	テーブル名は Product のままにします。

   ![](../Images/lab-02/image152.png)
 
9.	次へを選択します。

10.	[宛先の設定を選択する] ダイアログが開きます。今度は、自動設定を使用し、それによってデータの完全な更新が行われます。また、必要に応じて列の名前も変更されま す。設定の保存を選択します。

   ![](../Images/lab-02/image158.png)

11.	Power Query のウィンドウに戻ります。右下隅を見ると、データ同期先がレイクハウス
    に設定されています。

12.	同様に、次のクエリのデータ同期先を設定します。
    a.	Product Details
    b.	Reseller
    c.	Sales
    d.	Date

   ![](../Images/lab-02/image161.png)
 
13.	ADLS から Lakehouse にデータを取り込むデータ フローがあります。このデータフローを公開してみましょう。右下隅の公開を選択します。
    FAIAD_<ユーザー名> ワークスペースに自動的に戻ります。データフローが更新されるまでに、数分かかる場合があります。
    次のラボでは、他のデータ ソースからデータを取り込みます。
 
    リファレンス
Fabric Analyst in a Day (FAIAD) では、Microsoft Fabric で使用できる主要な機能の一部をご紹介します。サービスのメニューにあるヘルプ (?) セクションには、いくつかの優れたリソースへのリンクがあります。

   ![](../Images/lab-02/image168.png)

Microsoft Fabric の次のステップに役立つリソースをいくつか以下に紹介します。

- ブログ記事で Microsof t Fabric のGA に関するお知らせの全文を確認する
- ガイド付きツアーを通じて Fabric を探索する
- Microsof t Fabric の無料試用版にサインアップする
- Microsof t Fabric のWeb サイトにアクセスする
- Fabric の学習モジュールで新しいスキルを学ぶ
- Fabric の技術ドキュメントを参照する
 
- Fabric 入門編の無料のe-book を読む
- Fabric コミュニティに参加し、質問の投稿やフィードバックの共有を行い、他のユーザーから学びを得る
より詳しい Fabric  エクスペリエンスのお知らせに関するブログを参照してください。

- Fabric の Data Factory エクスペリエンスに関するブログ
- Fabric のSynapse Data Engineering エクスペリエンスに関するブログ
- Fabric のSynapse Data Science エクスペリエンスに関するブログ
- Fabric のSynapse Data Warehousing エクスペリエンスに関するブログ
- Fabric のSynapse Real-Time Analytics エクスペリエンスに関するブログ
- Power BI のお知らせに関するブログ
- Fabric の Data Activator エクスペリエンスに関するブログ
- Fabric の管理とガバナンスに関するブログ
- Fabric の OneLake に関するブログ
- Dataverse とMicrosof t Fabric の統合に関するブログ



© 2023 Microsoft Corporation. All rights reserved.

このデモ/ラボを使用すると、次の条件に同意したことになります。

このデモ/ラボで説明するテクノロジまたは機能は、ユーザーのフィードバックを取得 し、学習エクスペリエンスを提供するために、Microsoft Corporation によって提供されます。ユーザーは、このようなテクノロジおよび機能を評価し、Microsoft にフィードバックを提供するためにのみデモ/ラボを使用できます。それ以外の目的には使用できませ ん。このデモ/ラボまたはその一部を、変更、コピー、配布、送信、表示、実行、再現、 発行、ライセンス、著作物の作成、転送、または販売することはできません。
複製または再頒布のために他のサーバーまたは場所にデモ/ラボ (またはその一部) をコピーまたは複製することは明示的に禁止されています。
 
このデモ/ラボは、前に説明した目的のために複雑なセットアップまたはインストールを 必要としないシミュレーション環境で潜在的な新機能や概念などの特定のソフトウェアテクノロジ/製品の機能を提供します。このデモ/ラボで表されるテクノロジ/概念は、フル機能を表していない可能性があり、最終バージョンと動作が異なることがあります。また、そのような機能や概念の最終版がリリースされない場合があります。物理環境でこのような機能を使用するエクスペリエンスが異なる場合もあります。
フィードバック。このデモ/ラボで説明されているテクノロジ、機能、概念に関する フィードバックをMicrosoft に提供する場合、ユーザーは任意の方法および目的でユー
ザーのフィードバックを使用、共有、および商品化する権利を無償で Microsoft に提供するものとします。また、ユーザーは、フィードバックを含む Microsoft のソフトウェアまたはサービスの特定部分を使用したり特定部分とインターフェイスを持ったりする製 品、テクノロジ、サービスに必要な特許権を無償でサード パーティに付与します。ユーザーは、フィードバックを含めるために Microsoft がサード パーティにソフトウェアま たはドキュメントをライセンスする必要があるライセンスの対象となるフィードバックを提供しません。これらの権限は、本契約の後も存続します。
Microsoft Corporation は、明示、黙示、または法律上にかかわらず、商品性のすべての保証および条件、特定の目的、タイトル、非侵害に対する適合性など、デモ/ラボに関する すべての保証および条件を拒否します。Microsoft は、デモ/ラボから派生する結果、出力の正確さ、任意の目的に対するデモ/ラボに含まれる情報の適合性に関して、いかなる 保証または表明もしません。
免責事項

このデモ/ラボには、Microsoft Power BI の新機能と機能強化の一部のみが含まれています。一部の機能は、製品の将来のリリースで変更される可能性があります。このデモ/ラ ボでは、新機能のすべてではなく一部について学習します。
